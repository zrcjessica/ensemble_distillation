## Defaults for DREAM-RNN (lentiMPRA task)
## Based on DREAM paper specifications, adapted for lentiMPRA
epochs:
  desc: Number of epochs to train over
  value: 80  # DREAM paper: 80 epochs
batch_size:
  desc: Size of each mini-batch
  value: 1024  # DREAM paper: batch size 1,024
loss_fxn:
  desc: Loss function
  value: 'mse'
activation:
  desc: Default activation function to use throughout model
  value: 'relu'
first_activation:
  desc: First activation function used in model
  value: 'relu'
optimizer:
  desc: Name of optimizer to use
  value: 'AdamW'  # DREAM paper: AdamW with weight_decay=0.01
optim_lr:
  desc: Learning rate used by optimizer
  value: 0.005  # DREAM paper: max LR 0.005
early_stopping:
  desc: If true, train with early stopping
  value: false  # DREAM paper: no early stopping, use one-cycle LR
es_patience:
  desc: Patience to use for early stopping
  value: 10
lr_decay:
  desc: If true, train with learning rate decay
  value: false  # DREAM paper: use one-cycle LR policy instead
distill:
  desc: If true, model is distilled
  value: false
downsample:
  desc: Downsample training data ([0, 1])
  value: 1.0
std:
  desc: If true, predict standard deviation
  value: false
evoaug:
  desc: If true, train w/ EvoAug
  value: false

# DREAM-RNN specific parameters
dropout:
  desc: Dropout rate
  value: 0.2
kernel_sizes:
  desc: Kernel sizes for first layer block
  value: [9, 15]  # DREAM paper: kernel sizes 9 and 15
lstm_hidden_channels:
  desc: Hidden dimensions for Bi-LSTM
  value: 320  # DREAM paper: 320 hidden dimensions each (640 total)

# Uncertainty heads (aligns with DEGU paper and lentiMPRA protocol)
aleatoric:
  desc: If true, predict aleatoric uncertainty (replicate std)
  value: false
epistemic:
  desc: If true, predict epistemic uncertainty (via ensemble std distillation)
  value: false
